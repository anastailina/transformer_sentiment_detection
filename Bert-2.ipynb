{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUz2KZJv5dTG"
      },
      "source": [
        "## Import all necessary dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0NYJBLL5KKi",
        "outputId": "7dafc779-5091-48b7-e75c-ddf162d9f74b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting simpletransformers\n",
            "  Downloading simpletransformers-0.63.9-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.5/250.5 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from simpletransformers) (2022.6.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from simpletransformers) (1.10.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb>=0.10.32\n",
            "  Downloading wandb-0.13.10-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers>=4.6.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit\n",
            "  Downloading streamlit-1.19.0-py2.py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.8/dist-packages (from simpletransformers) (4.64.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from simpletransformers) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from simpletransformers) (1.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from simpletransformers) (1.22.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from simpletransformers) (2.11.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from simpletransformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->simpletransformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->simpletransformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->simpletransformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb>=0.10.32->simpletransformers) (8.1.3)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb>=0.10.32->simpletransformers) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb>=0.10.32->simpletransformers) (3.19.6)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb>=0.10.32->simpletransformers) (57.4.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from wandb>=0.10.32->simpletransformers) (4.5.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb>=0.10.32->simpletransformers) (5.4.8)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.16.0-py2.py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->simpletransformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->simpletransformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->simpletransformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->simpletransformers) (4.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets->simpletransformers) (2023.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets->simpletransformers) (3.8.4)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets->simpletransformers) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->simpletransformers) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->simpletransformers) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->simpletransformers) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->simpletransformers) (1.2.0)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit->simpletransformers) (4.2.2)\n",
            "Collecting blinker>=1.0.0\n",
            "  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.8/dist-packages (from streamlit->simpletransformers) (5.3.0)\n",
            "Collecting watchdog\n",
            "  Downloading watchdog-2.3.1-py3-none-manylinux2014_x86_64.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from streamlit->simpletransformers) (8.4.0)\n",
            "Collecting validators>=0.2\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from streamlit->simpletransformers) (6.2)\n",
            "Collecting semver\n",
            "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from streamlit->simpletransformers) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.8/dist-packages (from streamlit->simpletransformers) (6.0.0)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.8/dist-packages (from streamlit->simpletransformers) (1.5.1)\n",
            "Collecting rich>=10.11.0\n",
            "  Downloading rich-13.3.2-py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.7/238.7 KB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pympler>=0.9\n",
            "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 KB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->simpletransformers) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->simpletransformers) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->simpletransformers) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->simpletransformers) (2.16.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->simpletransformers) (2.2.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->simpletransformers) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->simpletransformers) (1.51.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->simpletransformers) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->simpletransformers) (0.4.6)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (4.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (3.1.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.12.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.10.32->simpletransformers) (1.15.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->simpletransformers) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->simpletransformers) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->simpletransformers) (3.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->simpletransformers) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->simpletransformers) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->simpletransformers) (1.8.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=1.4->streamlit->simpletransformers) (3.15.0)\n",
            "Collecting markdown-it-py<3.0.0,>=2.2.0\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments<3.0.0,>=2.13.0\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from validators>=0.2->streamlit->simpletransformers) (4.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (5.12.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit->simpletransformers) (0.19.3)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (3.2.2)\n",
            "Building wheels for collected packages: seqeval, validators, pathtools\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=bbf75dad3924928890bc9810a6fb2dd5cbc7282697f5e23cf71bbbe0b30da011\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19581 sha256=6f5da218c7e5d24d497193e75554c6eb0928bcd4316b2e1caf0ea3d3a15e1eaf\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/09/72/3eb74d236bb48bd0f3c6c3c83e4e0c5bbfcbcad7c6c3539db8\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=74a79ed3f629909cd4ebb16a5d88746533c26597cbdf3a9ba05cfbc22aa23bfb\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built seqeval validators pathtools\n",
            "Installing collected packages: tokenizers, sentencepiece, pathtools, xxhash, watchdog, validators, smmap, setproctitle, sentry-sdk, semver, pympler, pygments, mdurl, docker-pycreds, dill, blinker, responses, pydeck, multiprocess, markdown-it-py, huggingface-hub, gitdb, transformers, seqeval, rich, GitPython, wandb, streamlit, datasets, simpletransformers\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.31 blinker-1.5 datasets-2.10.1 dill-0.3.6 docker-pycreds-0.4.0 gitdb-4.0.10 huggingface-hub-0.12.1 markdown-it-py-2.2.0 mdurl-0.1.2 multiprocess-0.70.14 pathtools-0.1.2 pydeck-0.8.0 pygments-2.14.0 pympler-1.0.1 responses-0.18.0 rich-13.3.2 semver-2.13.0 sentencepiece-0.1.97 sentry-sdk-1.16.0 seqeval-1.2.2 setproctitle-1.3.2 simpletransformers-0.63.9 smmap-5.0.0 streamlit-1.19.0 tokenizers-0.13.2 transformers-4.26.1 validators-0.20.0 wandb-0.13.10 watchdog-2.3.1 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardx\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardx) (3.19.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardx) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardx) (23.0)\n",
            "Installing collected packages: tensorboardx\n",
            "Successfully installed tensorboardx-2.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (7.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (3.6.2)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (7.9.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.3.4)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (3.0.5)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (2.0.10)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (2.14.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.16.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.4)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.2.0)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.6.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (22.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.12.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.15.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.15.0)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n",
            "Enabling notebook extension jupyter-js-widgets/extension...\n",
            "Paths used for configuration of notebook: \n",
            "    \t/root/.jupyter/nbconfig/notebook.json\n",
            "Paths used for configuration of notebook: \n",
            "    \t\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n",
            "Paths used for configuration of notebook: \n",
            "    \t/root/.jupyter/nbconfig/notebook.json\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 KB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (1.22.4)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from nlpaug) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (3.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown>=4.0.0->nlpaug) (4.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.0->nlpaug) (2022.7.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (4.0.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ray\n",
            "  Downloading ray-2.3.0-cp38-cp38-manylinux2014_x86_64.whl (58.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from ray) (1.22.4)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.8/dist-packages (from ray) (1.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray) (1.0.4)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from ray) (22.2.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray) (8.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from ray) (3.9.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray) (3.19.6)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.8/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from ray) (1.51.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from ray) (2.25.1)\n",
            "Collecting virtualenv>=20.0.24\n",
            "  Downloading virtualenv-20.20.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from ray) (6.0)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 KB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray) (3.0.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray) (5.12.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (1.26.14)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.15.0)\n",
            "Installing collected packages: distlib, virtualenv, ray\n",
            "Successfully installed distlib-0.3.6 ray-2.3.0 virtualenv-20.20.0\n"
          ]
        }
      ],
      "source": [
        "%pip install simpletransformers\n",
        "%pip install tensorboardx\n",
        "%pip install transformers\n",
        "%pip install sentencepiece\n",
        "%pip install ipywidgets\n",
        "!jupyter nbextension enable --py widgetsnbextension\n",
        "%pip install nlpaug\n",
        "%pip install ray\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHR4XKJRTmIz",
        "outputId": "4d51bc07-6421-40b6-85cc-e447901e0e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ray[tune] in /usr/local/lib/python3.8/dist-packages (2.3.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (3.19.6)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (4.3.3)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (2.25.1)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.51.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (22.2.0)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (20.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (3.9.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (8.1.3)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.22.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (6.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.0.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (0.8.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.3.5)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (2.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=1.9->ray[tune]) (23.0)\n",
            "Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray[tune]) (3.0.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray[tune]) (0.3.6)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray[tune]) (5.12.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray[tune]) (0.19.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->ray[tune]) (2022.7.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->ray[tune]) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->ray[tune]) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->ray[tune]) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->ray[tune]) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray[tune]) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->ray[tune]) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install ray[tune]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00IwCUe85cbp",
        "outputId": "b5122a0b-9a64-4781-8fa1-dbd429509e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs, MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
        "from urllib import request\n",
        "import pandas as pd\n",
        "import logging\n",
        "import torch\n",
        "from collections import Counter, defaultdict\n",
        "from ast import literal_eval\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "\n",
        "from transformers import RobertaTokenizer\n",
        "from transformers import RobertaPreTrainedModel, RobertaModel\n",
        "\n",
        "import nlpaug.augmenter.word as naw\n",
        "from sklearn.utils import shuffle\n",
        "from ray import tune\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "  print('WARNING: You may want to change the runtime to GPU for faster training!')\n",
        "  device = 'cpu'\n",
        "else:\n",
        "  device = 'cuda:0'\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwkaPSfa6Q7i"
      },
      "outputs": [],
      "source": [
        "# prepare logger\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxkW1D-j6T99",
        "outputId": "8faef552-68fd-43bd-a7c3-73309f85a426"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd27ac2ea50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "rng_seed = 42\n",
        "torch.manual_seed(rng_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHM4do_X6dSr"
      },
      "source": [
        "## Loading the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPdUo3jK6kEz",
        "outputId": "3cf50d2a-9c01-48fd-b22f-85dbae99ead9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Connect google drive on colab \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtfkUuTP620I"
      },
      "outputs": [],
      "source": [
        "data_folder = \"dontpatronizeme_v1.4/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nRiHRnB_eSj"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Class from 'dont_patronize_me' GitHub RePo\n",
        "\n",
        "# It is used to manipulate the dont_patronize_me dataset and \n",
        "# to merge labels into binary classfications\n",
        "\n",
        "class DontPatronizeMe:\n",
        "\n",
        "  def __init__(self, train_path, test_path):\n",
        "\n",
        "    self.train_path = train_path\n",
        "    self.test_path = test_path\n",
        "    self.train_task1_df = None\n",
        "    self.train_task2_df = None\n",
        "    self.test_set_df = None\n",
        "\n",
        "  def load_task1(self):\n",
        "    \"\"\"\n",
        "    Load task 1 training set and convert the tags into binary labels. \n",
        "    Paragraphs with original labels of 0 or 1 are considered to be negative examples of PCL and will have the label 0 = negative.\n",
        "    Paragraphs with original labels of 2, 3 or 4 are considered to be positive examples of PCL and will have the label 1 = positive.\n",
        "    It returns a pandas dataframe with paragraphs and labels.\n",
        "    \"\"\"\n",
        "    rows=[]\n",
        "    with open(self.train_path) as f: #no joining, just the exact path otherwise, it seems to fail\n",
        "      for line in f.readlines()[4:]:  \n",
        "\n",
        "        par_id=line.strip().split('\\t')[0]\n",
        "        art_id = line.strip().split('\\t')[1]\n",
        "        keyword=line.strip().split('\\t')[2]\n",
        "        country=line.strip().split('\\t')[3]\n",
        "        t=line.strip().split('\\t')[4]#.lower()\n",
        "        l=line.strip().split('\\t')[-1]\n",
        "        # if l=='3':\n",
        "        #   print(t)\n",
        "        #   print(\"----------\")\n",
        "        if l=='0' or l=='1':\n",
        "          lbin=0\n",
        "        else:\n",
        "          lbin=1\n",
        "        rows.append(\n",
        "          {'par_id':par_id,\n",
        "          'art_id':art_id,\n",
        "          'keyword':keyword,\n",
        "          'country':country,\n",
        "          'text':t, \n",
        "          'label':lbin, \n",
        "          'orig_label':l\n",
        "          }\n",
        "          )\n",
        "    df=pd.DataFrame(rows, columns=['par_id', 'art_id', 'keyword', 'country', 'text', 'label', 'orig_label']) \n",
        "    self.train_task1_df = df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OAsHapZAYOb"
      },
      "outputs": [],
      "source": [
        "#Get the data ad DontPatronizeMe class\n",
        "\n",
        "dont_patronize_me= DontPatronizeMe('/content/gdrive/MyDrive/NLP Coursework/dontpatronizeme_pcl.tsv', None) \n",
        "dont_patronize_me.load_task1()\n",
        "\n",
        "open('/content/gdrive/MyDrive/NLP Coursework/dev_semeval_parids-labels.csv')\n",
        "open('/content/gdrive/MyDrive/NLP Coursework/train_semeval_parids-labels.csv')\n",
        "\n",
        "training_data_ids = pd.read_csv('/content/gdrive/MyDrive/NLP Coursework/train_semeval_parids-labels.csv')\n",
        "evaluation_data_ids = pd.read_csv('/content/gdrive/MyDrive/NLP Coursework/dev_semeval_parids-labels.csv')\n",
        "\n",
        "training_data_ids.par_id = training_data_ids.par_id.astype(str)\n",
        "evaluation_data_ids.par_id = evaluation_data_ids.par_id.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yII4x4r7TmI6"
      },
      "outputs": [],
      "source": [
        "#Get the data ad DontPatronizeMe class\n",
        "\n",
        "dont_patronize_me= DontPatronizeMe('data/dontpatronizeme_pcl.tsv', None) \n",
        "dont_patronize_me.load_task1()\n",
        "\n",
        "open('data/dev_semeval_parids-labels.csv')\n",
        "evaluation_data_ids = pd.read_csv('data/dev_semeval_parids-labels.csv')\n",
        "\n",
        "open('data/train_semeval_parids-labels.csv')\n",
        "training_data_ids = pd.read_csv('data/train_semeval_parids-labels.csv')\n",
        "\n",
        "training_data_ids.par_id = training_data_ids.par_id.astype(str)\n",
        "evaluation_data_ids.par_id = evaluation_data_ids.par_id.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxShFuwRTmI7"
      },
      "outputs": [],
      "source": [
        "# Build train set with text and labels\n",
        "\n",
        "train_rows = [] # will contain label and text\n",
        "for idx in range(len(training_data_ids)):\n",
        "    parid = training_data_ids.par_id[idx]\n",
        "    #print(parid)\n",
        "    # select row from original dataset to retrieve columns with training information\n",
        "    text = dont_patronize_me.train_task1_df.loc[dont_patronize_me.train_task1_df.par_id == parid].text.values[0]\n",
        "    label = dont_patronize_me.train_task1_df.loc[dont_patronize_me.train_task1_df.par_id == parid].label.values[0]\n",
        "    train_rows.append({\n",
        "        'texts':text,\n",
        "        'labels':label\n",
        "    })\n",
        "    train_set_raw = pd.DataFrame(train_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkCYOv7aTmI7"
      },
      "outputs": [],
      "source": [
        "# Build evaluation set with text and labels\n",
        "eval_rows = []\n",
        "for idx in range(len(evaluation_data_ids)):\n",
        "    parid = evaluation_data_ids.par_id[idx]\n",
        "    #print(parid)\n",
        "    # select row from original dataset to retrieve columns with training information\n",
        "    text = dont_patronize_me.train_task1_df.loc[dont_patronize_me.train_task1_df.par_id == parid].text.values[0]\n",
        "    label = dont_patronize_me.train_task1_df.loc[dont_patronize_me.train_task1_df.par_id == parid].label.values[0]\n",
        "    eval_rows.append({\n",
        "        #'par_id':parid,\n",
        "        'texts':text,\n",
        "        'labels':label,\n",
        "    })\n",
        "\n",
        "eval_set = pd.DataFrame(eval_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVpKlUMQTmI8"
      },
      "outputs": [],
      "source": [
        "# Rebuilt Official train set with keyword and country codes\n",
        "\n",
        "additional_rows = [] # will contain par_id, label and text\n",
        "for idx in range(len(training_data_ids)):  \n",
        "  parid = training_data_ids.par_id[idx]\n",
        "  #print(parid)\n",
        "  # select row from original dataset to retrieve columns with training information\n",
        "  text = dont_patronize_me.train_task1_df.loc[dont_patronize_me.train_task1_df.par_id == parid].text.values[0]\n",
        "  label = dont_patronize_me.train_task1_df.loc[dont_patronize_me.train_task1_df.par_id == parid].label.values[0]\n",
        "  country = dont_patronize_me.train_task1_df.loc[dont_patronize_me.train_task1_df.par_id == parid].country.values[0]\n",
        "  keyword = dont_patronize_me.train_task1_df.loc[dont_patronize_me.train_task1_df.par_id == parid].keyword.values[0]\n",
        "  additional_rows.append({\n",
        "      #'par_id':parid,\n",
        "      'texts':text,\n",
        "      'labels':label,\n",
        "      'country':country,\n",
        "      'keyword':keyword\n",
        "  })\n",
        "  all_cols_train_set = pd.DataFrame(additional_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToQQRhPXTmI8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split train set into train and validation sets\n",
        "train_set, val_set = train_test_split(train_set_raw, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save indi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHvCRvviTmI9"
      },
      "outputs": [],
      "source": [
        "# Save validation set\n",
        "val_set.to_csv('/content/gdrive/MyDrive/NLP Coursework/val_set.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px0IXByxnJxF",
        "outputId": "c3ffefb6-e82a-449a-d3f3-a287d76f17e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['love movie', 'movie boring', 'movie great']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preproc_text(text):\n",
        "  # Tokenization\n",
        "  tokens = word_tokenize(text.lower())\n",
        "  # Stop words removal\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = [word for word in tokens if word not in stop_words] \n",
        "  # Punctuation removal\n",
        "  tokens = [word for word in tokens if word not in string.punctuation]\n",
        "\n",
        "  # Lemmatization\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "  return tokens\n",
        "\n"
      ],
      "metadata": {
        "id": "3zXs9vHnz584"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_raw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5oKKiV8t0adX",
        "outputId": "553b658a-9cbe-4a2c-f579-5b83a23e5f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  texts  labels  \\\n",
              "0     The scheme saw an estimated 150,000 children f...       1   \n",
              "1     Durban 's homeless communities reconciliation ...       1   \n",
              "2     The next immediate problem that cropped up was...       1   \n",
              "3     Far more important than the implications for t...       1   \n",
              "4     To strengthen child-sensitive social protectio...       1   \n",
              "...                                                 ...     ...   \n",
              "8370  Rescue teams search for survivors on the rubbl...       0   \n",
              "8371  The launch of ' Happy Birthday ' took place la...       0   \n",
              "8372  The unrest has left at least 20,000 people dea...       0   \n",
              "8373  You have to see it from my perspective . I may...       0   \n",
              "8374  Yet there was one occasion when we went to the...       0   \n",
              "\n",
              "                                            PreprocText  \n",
              "0     scheme saw estimated 150,000 child poor family...  \n",
              "1     durban 's homeless community reconciliation lunch  \n",
              "2     next immediate problem cropped assist unfortun...  \n",
              "3     far important implication economy god dollar l...  \n",
              "4     strengthen child-sensitive social protection s...  \n",
              "...                                                 ...  \n",
              "8370  rescue team search survivor rubble building fo...  \n",
              "8371  launch happy birthday took place last saturday...  \n",
              "8372  unrest left least 20,000 people dead nigeria m...  \n",
              "8373  see perspective may journalist strictest sense...  \n",
              "8374  yet one occasion went scene triple murder woma...  \n",
              "\n",
              "[8375 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42810fbe-7729-45e7-949b-2c0ef31b9831\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "      <th>PreprocText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The scheme saw an estimated 150,000 children f...</td>\n",
              "      <td>1</td>\n",
              "      <td>scheme saw estimated 150,000 child poor family...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Durban 's homeless communities reconciliation ...</td>\n",
              "      <td>1</td>\n",
              "      <td>durban 's homeless community reconciliation lunch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The next immediate problem that cropped up was...</td>\n",
              "      <td>1</td>\n",
              "      <td>next immediate problem cropped assist unfortun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Far more important than the implications for t...</td>\n",
              "      <td>1</td>\n",
              "      <td>far important implication economy god dollar l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>To strengthen child-sensitive social protectio...</td>\n",
              "      <td>1</td>\n",
              "      <td>strengthen child-sensitive social protection s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8370</th>\n",
              "      <td>Rescue teams search for survivors on the rubbl...</td>\n",
              "      <td>0</td>\n",
              "      <td>rescue team search survivor rubble building fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8371</th>\n",
              "      <td>The launch of ' Happy Birthday ' took place la...</td>\n",
              "      <td>0</td>\n",
              "      <td>launch happy birthday took place last saturday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8372</th>\n",
              "      <td>The unrest has left at least 20,000 people dea...</td>\n",
              "      <td>0</td>\n",
              "      <td>unrest left least 20,000 people dead nigeria m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8373</th>\n",
              "      <td>You have to see it from my perspective . I may...</td>\n",
              "      <td>0</td>\n",
              "      <td>see perspective may journalist strictest sense...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8374</th>\n",
              "      <td>Yet there was one occasion when we went to the...</td>\n",
              "      <td>0</td>\n",
              "      <td>yet one occasion went scene triple murder woma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8375 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42810fbe-7729-45e7-949b-2c0ef31b9831')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42810fbe-7729-45e7-949b-2c0ef31b9831 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42810fbe-7729-45e7-949b-2c0ef31b9831');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preproc = []\n",
        "\n",
        "for idx in range(len(train_set_raw)):\n",
        "  text = train_set_raw.loc[idx, 'texts']\n",
        "  tokens = preproc_text(text)\n",
        "  preproc.append(tokens)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hkM9Nubkzo0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Histogram of preproc lengths\n",
        "plt.hist([len(x) for x in preproc], bins = np.arange(0,500,5))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "IomWf2xq1sE6",
        "outputId": "b3b2460e-e7f1-4851-8a92-62e389061d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_preproc=[]\n",
        "for words in preproc:\n",
        "  padded_words = words[:128]+['<pad>']*(128 - len(words))\n",
        "  padded_preproc.append(padded_words)"
      ],
      "metadata": {
        "id": "H_XBgIUH4TqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Histogram of preproc lengths\n",
        "plt.hist([len(x) for x in padded_preproc], bins = np.arange(0,500,5))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "sEi-r0DrMrT5",
        "outputId": "fb6399ad-50b6-4834-d94a-2d0bb348a17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join tokens back to text\n",
        "preprocessed_data = [' '.join(text) for text in preproc]"
      ],
      "metadata": {
        "id": "k4sviqcD45f-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(max_features=1000)\n",
        "train_set_raw['PreprocText'] = preprocessed_data\n",
        "X = vectorizer.fit(train_set_raw['PreprocText'])"
      ],
      "metadata": {
        "id": "bc19XpO59tEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train set into train and validation sets\n",
        "train_set, val_set = train_test_split(train_set_raw, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "jdN2UkTLAjCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "UAVLQ1px9lCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SIMPLE METHOD I**: Bag of words Naive Bayes (no upsampling)\n",
        "\n",
        "```\n",
        "`# This is formatted as code`\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "eThfQKUkHrBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create a bag of words\n",
        "\n",
        "X_train = X.transform(train_set['PreprocText'])\n",
        "y_train = train_set['labels']\n",
        "X_test = X.transform(val_set['PreprocText'])\n",
        "y_test = val_set['labels']\n"
      ],
      "metadata": {
        "id": "I2JIYmIi9TPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YT4VI5r9TCT",
        "outputId": "957c2487-a1e1-478e-a183-23e994e53018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1675, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "I85UM1GuFoDg",
        "outputId": "1442cf26-ccb5-4b90-b994-99cec369c90b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the classifier\n",
        "y_pred = clf.predict(X_test)\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuXvDuwFFn7r",
        "outputId": "480f9971-ea90-48bc-83d5-5cafae68e495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8847761194029851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the confusion matrix and classification report\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTrZAzqbFnxF",
        "outputId": "a1f586d8-7214-48c9-d94a-56091adc4661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[1423   85]\n",
            " [ 108   59]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.94      1508\n",
            "           1       0.41      0.35      0.38       167\n",
            "\n",
            "    accuracy                           0.88      1675\n",
            "   macro avg       0.67      0.65      0.66      1675\n",
            "weighted avg       0.88      0.88      0.88      1675\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method II SVM**"
      ],
      "metadata": {
        "id": "N6KS4Rg6aRQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC"
      ],
      "metadata": {
        "id": "4gd9sXu7aTgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LinearSVC()"
      ],
      "metadata": {
        "id": "7vrAUpvFaTYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "4QFyIt_taTR_",
        "outputId": "95287609-f1b1-457b-b796-af2581a053b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC()"
            ],
            "text/html": [
              "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the confusion matrix and classification report\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_C39J7xaTF3",
        "outputId": "dfc9a9df-25a9-44a0-dd1d-f3b281a9a0d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[1419   89]\n",
            " [ 131   36]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93      1508\n",
            "           1       0.29      0.22      0.25       167\n",
            "\n",
            "    accuracy                           0.87      1675\n",
            "   macro avg       0.60      0.58      0.59      1675\n",
            "weighted avg       0.85      0.87      0.86      1675\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method III logistic regression"
      ],
      "metadata": {
        "id": "21gUOJ7fpOcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "02czlZpPpIBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "axDSkiwKpI_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression()"
      ],
      "metadata": {
        "id": "SqUDFtpnaS_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "iEf360twaS3S",
        "outputId": "d94f6e09-676b-4c57-f504-7a0cbb475aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = logreg.predict(X_test)"
      ],
      "metadata": {
        "id": "NP0rQRkLqOqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the confusion matrix and classification report\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIi8h9F9qOZT",
        "outputId": "b42cc333-52aa-47ac-ee4f-5f64d7848d0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[1469   39]\n",
            " [ 139   28]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94      1508\n",
            "           1       0.42      0.17      0.24       167\n",
            "\n",
            "    accuracy                           0.89      1675\n",
            "   macro avg       0.67      0.57      0.59      1675\n",
            "weighted avg       0.86      0.89      0.87      1675\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple Method III**: FeedForward **NN**"
      ],
      "metadata": {
        "id": "xnb_Xr1FIiLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qISCaYT9Ih7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word2idx(tokenized_corpus):\n",
        "  vocabulary = []\n",
        "  for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "        if token not in vocabulary:\n",
        "            vocabulary.append(token)\n",
        "  \n",
        "  word2idx = {w: idx+1 for (idx, w) in enumerate(vocabulary)}\n",
        "  # we reserve the 0 index for the padding token\n",
        "  word2idx['<pad>'] = 0\n",
        "  \n",
        " \n",
        "  return word2idx"
      ],
      "metadata": {
        "id": "V6ov0vkPFnhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(padded_preproc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Do4kR9gJW6P",
        "outputId": "ef3a14f3-954c-4804-cd20-ff0a91b98cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8375"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx=get_word2idx(padded_preproc)"
      ],
      "metadata": {
        "id": "dDVby5BWJWsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vectorize sentences\n",
        "vectorized_sents = [[word2idx[tok] for tok in sent if tok in word2idx] for sent in padded_preproc]"
      ],
      "metadata": {
        "id": "8Ls8mI8oJWb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tensor = torch.zeros((len(vectorized_sents), 128)).long()"
      ],
      "metadata": {
        "id": "C2-WTNOqJWDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, sent in enumerate(vectorized_sents):\n",
        "  sent_tensor[idx,:] = torch.LongTensor(sent)"
      ],
      "metadata": {
        "id": "RvJh1UR0Ol5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_tensor = torch.FloatTensor(train_set_raw['labels'])"
      ],
      "metadata": {
        "id": "XZHXLWUZPHRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "num_range = range(len(label_tensor))\n",
        "random_subset = random.sample(num_range, int(len(label_tensor)*0.2))\n",
        "complement_subset = np.setdiff1d(num_range, random_subset)"
      ],
      "metadata": {
        "id": "FdOA11WZP-Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = label_tensor[random_subset]\n",
        "y_train = label_tensor[complement_subset]\n",
        "X_test = sent_tensor[random_subset]\n",
        "X_train = sent_tensor[complement_subset]"
      ],
      "metadata": {
        "id": "pOmgViEYQ3LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "J7OnoRJz9Skx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FFNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, num_classes):  \n",
        "        super(FFNN, self).__init__()\n",
        "        \n",
        "        # embedding (lookup layer) layer\n",
        "        # padding_idx argument makes sure that the 0-th token in the vocabulary\n",
        "        # is used for padding purposes i.e. its embedding will be a 0-vector\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        \n",
        "        # hidden layer\n",
        "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
        "        \n",
        "        # activation\n",
        "        self.relu1 = nn.ReLU()\n",
        "        \n",
        "        # hidden layer\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        # activation\n",
        "\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # linear layet\n",
        "\n",
        "        self.fc3 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "        # sigmoid\n",
        "\n",
        "        # self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x has shape (batch_size, max_sent_len)\n",
        "\n",
        "        embedded = self.embedding(x)\n",
        "        # `embedded` has shape (batch size, max_sent_len, embedding dim)\n",
        "\n",
        "        ########################################################################\n",
        "        # Q: Compute the average embeddings of shape (batch_size, embedding_dim)\n",
        "        ########################################################################\n",
        "        # Implement averaging that ignores padding (average using actual sentence lengths).\n",
        "        # Hint: You need to ignore the <pad> token when averaging.\n",
        "        # How does this affect the result?\n",
        "        \n",
        "        sent_lens = x.ne(0).sum(1, keepdims=True)\n",
        "        averaged = embedded.sum(1) / sent_lens\n",
        "\n",
        "        out = self.fc1(averaged)\n",
        "        out = self.relu1(out)\n",
        "        # out = self.fc2(out)\n",
        "        # out = self.relu2(out)\n",
        "        out = self.fc3(out)\n",
        "        # out = self.sigmoid(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Nd97wZeHSQGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "Izz1minCTIW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the seed before every model construction for reproducible results\n",
        "# fix_seed()\n",
        "\n",
        "# we will train for N epochs (The model will see the corpus N times)\n",
        "EPOCHS = 25\n",
        "\n",
        "# Learning rate is initially set to 0.5\n",
        "LRATE = 0.05\n",
        "\n",
        "# we define our embedding dimension (dimensionality of the output of the first layer)\n",
        "EMBEDDING_DIM = 300\n",
        "\n",
        "# dimensionality of the output of the second hidden layer\n",
        "HIDDEN_DIM = 50\n",
        "\n",
        "# the output dimension is the number of classes, 1 for binary classification\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "# Construct the model\n",
        "model = FFNN(EMBEDDING_DIM, HIDDEN_DIM, len(word2idx)+1, OUTPUT_DIM)\n",
        "\n",
        "# Print the model\n",
        "print(model)\n",
        "\n",
        "# we use the stochastic gradient descent (SGD) optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=LRATE)\n",
        "\n",
        "# we use the binary cross-entropy loss with sigmoid (applied to logits) \n",
        "# Recall that we did not apply any activation to our output layer, hence we need\n",
        "# to make our outputs look like probabilities.\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Input and label tensors\n",
        "feature = X_train\n",
        "target = y_train\n",
        "\n",
        "################\n",
        "# Start training\n",
        "################\n",
        "print(f'Will train for {EPOCHS} epochs')\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "  # to ensure the dropout (explained later) is \"turned on\" while training\n",
        "  # good practice to include even if do not use here\n",
        "  model.train()\n",
        "  \n",
        "  # we zero the gradients as they are not removed automatically\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  # squeeze is needed as the predictions will have the shape (batch size, 1)\n",
        "  # and we need to remove the dimension of size 1\n",
        "  predictions = model(feature).squeeze(1)\n",
        "\n",
        "  # Compute the loss\n",
        "  loss = loss_fn(predictions, target)\n",
        "  train_loss = loss.item()\n",
        "\n",
        "  # calculate the gradient of each parameter\n",
        "  loss.backward()\n",
        "\n",
        "  # update the parameters using the gradients and optimizer algorithm \n",
        "  optimizer.step()\n",
        "  \n",
        "  print(f'| Epoch: {epoch:02} | Train Loss: {train_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8v3FvmNSP23",
        "outputId": "30a5e043-5170-43f7-82bf-f4f3d8eaad49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FFNN(\n",
            "  (embedding): Embedding(26450, 300, padding_idx=0)\n",
            "  (fc1): Linear(in_features=300, out_features=50, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (fc3): Linear(in_features=50, out_features=1, bias=True)\n",
            ")\n",
            "Will train for 25 epochs\n",
            "| Epoch: 01 | Train Loss: 0.754\n",
            "| Epoch: 02 | Train Loss: 0.741\n",
            "| Epoch: 03 | Train Loss: 0.728\n",
            "| Epoch: 04 | Train Loss: 0.715\n",
            "| Epoch: 05 | Train Loss: 0.703\n",
            "| Epoch: 06 | Train Loss: 0.691\n",
            "| Epoch: 07 | Train Loss: 0.680\n",
            "| Epoch: 08 | Train Loss: 0.669\n",
            "| Epoch: 09 | Train Loss: 0.659\n",
            "| Epoch: 10 | Train Loss: 0.648\n",
            "| Epoch: 11 | Train Loss: 0.639\n",
            "| Epoch: 12 | Train Loss: 0.629\n",
            "| Epoch: 13 | Train Loss: 0.620\n",
            "| Epoch: 14 | Train Loss: 0.611\n",
            "| Epoch: 15 | Train Loss: 0.602\n",
            "| Epoch: 16 | Train Loss: 0.593\n",
            "| Epoch: 17 | Train Loss: 0.585\n",
            "| Epoch: 18 | Train Loss: 0.577\n",
            "| Epoch: 19 | Train Loss: 0.569\n",
            "| Epoch: 20 | Train Loss: 0.562\n",
            "| Epoch: 21 | Train Loss: 0.555\n",
            "| Epoch: 22 | Train Loss: 0.548\n",
            "| Epoch: 23 | Train Loss: 0.541\n",
            "| Epoch: 24 | Train Loss: 0.534\n",
            "| Epoch: 25 | Train Loss: 0.528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model(X_test)\n",
        "  y_pred = torch.round(torch.sigmoid(y_pred))\n",
        "\n",
        "# Print the confusion matrix and classification report\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-eeMNy8mBMw",
        "outputId": "a8be0e8c-7e72-4f38-dde6-861a7c4c0e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[1514    0]\n",
            " [ 161    0]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      1.00      0.95      1514\n",
            "         1.0       0.00      0.00      0.00       161\n",
            "\n",
            "    accuracy                           0.90      1675\n",
            "   macro avg       0.45      0.50      0.47      1675\n",
            "weighted avg       0.82      0.90      0.86      1675\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the model\n",
        "model = FFNN(EMBEDDING_DIM, HIDDEN_DIM, len(word2idx), OUTPUT_DIM)"
      ],
      "metadata": {
        "id": "CaZ2v4_ZSPtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(word2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKcXC4G-SPn4",
        "outputId": "1e07108a-7858-4b0e-bf4f-68a55a15c6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26449"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoAVnxHqSPh_",
        "outputId": "2f380fa4-56bb-4979-9069-6c0c04d78d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FFNN(\n",
              "  (embedding): Embedding(26449, 50, padding_idx=0)\n",
              "  (fc1): Linear(in_features=50, out_features=50, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(len(word2idx), 50)\n",
        "fc1 = nn.Linear(50, 50)\n",
        "  # activation\n",
        "relu1 = nn.ReLU()\n",
        "        \n",
        "        # output layer\n",
        "fc2 = nn.Linear(50, 1) \n",
        "\n",
        "\n",
        "sent_lens = X_train[0:16].ne(0).sum(1, keepdims=True)\n"
      ],
      "metadata": {
        "id": "zm1yNum_SPaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded = embedding(X_train[0:16])\n",
        "averaged = embedded.sum(1) / sent_lens\n",
        "\n",
        "fc2(relu1(fc1(averaged))).squeeze(1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zRnw5uJie_1",
        "outputId": "3a6057e2-f41a-460d-820b-a6e62f65ff3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16])"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(X_train[0:16]).squeeze(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ8eA7-njH6x",
        "outputId": "446fc721-d62a-46fb-b654-5d75fa7ba6ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0770, -0.1844, -0.1349, -0.0270, -0.1329, -0.0369, -0.0863, -0.1032,\n",
              "        -0.1133, -0.2335, -0.1391, -0.1201, -0.2389, -0.2016, -0.1156, -0.1312],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[len(x) for x in X_train]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjstSnEUlbMd",
        "outputId": "6c17cb7f-361c-4aa3-f22d-de71c8653c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " 128,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4_IzClSTmI9"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "imVpH2dbSOjn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qvTBf0hTmI9"
      },
      "source": [
        "### Downsampling of the majority class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbwM_dMPTmI9",
        "outputId": "be1c0fae-c7d5-4be0-f42f-049ce53b471a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn->imblearn) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn->imblearn) (1.23.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn->imblearn) (1.8.1)\n",
            "Collecting joblib>=1.1.1\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
            "Installing collected packages: joblib, imbalanced-learn, imblearn\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.0\n",
            "    Uninstalling joblib-1.1.0:\n",
            "      Successfully uninstalled joblib-1.1.0\n",
            "Successfully installed imbalanced-learn-0.10.1 imblearn-0.0 joblib-1.2.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_faZsxpTmI-"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVBLpfB9TmI-",
        "outputId": "8f46a845-6c62-4593-d834-23fd1198ae18"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Distribution of positive and negative examples after downsampling of negative examples')"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Use downsampling of negative examples to balance the dataset\n",
        "# https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.RandomUnderSampler.html\n",
        "\n",
        "# Split train set into positive and negative examples\n",
        "#positive = train_set[train_set['labels'] == 1]\n",
        "#negative = train_set[train_set['labels'] == 0]\n",
        "\n",
        "# Plot distribution of positive and negative examples\n",
        "fig, ax = plt.subplots()\n",
        "sns.countplot(x='labels', data=train_set, ax=ax)\n",
        "ax.set_title('Distribution of positive and negative examples')\n",
        "ax.set_xlabel('Labels')\n",
        "ax.set_ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "# Downsample negative examples\n",
        "rus = RandomUnderSampler(sampling_strategy = 0.3, random_state=42)\n",
        "X_res, y_res = rus.fit_resample(train_set[['texts']], train_set[['labels']])\n",
        "train_set_balanced = pd.concat([X_res, y_res], axis=1)\n",
        "\n",
        "# Plot distribution of positive and negative examples\n",
        "fig, ax = plt.subplots()\n",
        "sns.countplot(x='labels', data=train_set_balanced, ax=ax)   \n",
        "ax.set_title('Distribution of positive and negative examples after downsampling of negative examples')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj5DNrVzTmI_"
      },
      "source": [
        "### Augmentation via contextual word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eLSDsrwTmI_"
      },
      "outputs": [],
      "source": [
        "# Taken from https://neptune.ai/blog/data-augmentation-nlp\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEW7Kv6STmI_"
      },
      "outputs": [],
      "source": [
        "# Create a function for randomly apply contextual word embedding augmentation to a sleected number of both positive and negative examples \n",
        "\n",
        "def random_augment(dataframe, num_positive, num_negative, aug_p):\n",
        "\n",
        "    aug = naw.ContextualWordEmbsAug(\n",
        "        model_path='bert-base-uncased', action=\"substitute\", aug_p=aug_p)\n",
        "\n",
        "\n",
        "    augmented_positive = []\n",
        "    augmented_negative = []\n",
        "\n",
        "\n",
        "    negative_examples = dataframe[dataframe['labels'] == 0]['texts'].sample(num_negative, random_state=42)\n",
        "    positive_examples = dataframe[dataframe['labels'] == 1]['texts'].sample(num_positive, random_state=42)\n",
        "\n",
        "    for text_pos, text_neg in tqdm(zip(negative_examples, positive_examples)):\n",
        "        augmented_negative.append(aug.augment(text_neg))\n",
        "        augmented_positive.append(aug.augment(text_pos))\n",
        "\n",
        "    # Add augmented examples to the train set\n",
        "    new_negative = pd.DataFrame({'texts':augmented_negative, 'labels':0})\n",
        "    new_positive = pd.DataFrame({'texts':augmented_positive, 'labels':1})\n",
        "    new_data_frame = shuffle(pd.concat([dataframe, new_negative, new_positive], axis=0))\n",
        "\n",
        "    return new_data_frame\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "e7b04f201a0f42b68cb1379dd0d48486"
          ]
        },
        "id": "qNcfj3NiTmJA",
        "outputId": "563c4d6c-0d51-4bce-bfb4-dd19eeab22be"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7b04f201a0f42b68cb1379dd0d48486",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "aug_p = 0.3\n",
        "num_positive = 200\n",
        "num_negative = 200\n",
        "\n",
        "train_set_augmented_balanced = random_augment(train_set_balanced, num_positive, num_negative, aug_p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O6Q-LHwTmJA",
        "outputId": "bc4397f7-f6e3-4b82-d0f1-64b5b9ba7bee"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'num_positive' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Save augmented dataset to a csv\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_set_augmented_balanced\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/augmentations_\u001b[39m\u001b[39m{\u001b[39;00mnum_positive\u001b[39m}\u001b[39;00m\u001b[39m_.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_positive' is not defined"
          ]
        }
      ],
      "source": [
        "# Save augmented dataset to a csv\n",
        "train_set_augmented_balanced.to_csv(f'data/augmentations_{num_positive}_.csv') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rujfTK7YTmJA"
      },
      "source": [
        "## Creating custom DataSet Class for PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBu9xc17TmJB"
      },
      "outputs": [],
      "source": [
        "train_set_augmented_balanced = pd.read_csv('data/augmentations_200_.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCAs5QYyTmJB"
      },
      "outputs": [],
      "source": [
        "val_set = pd.read_csv('data/val_set.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdKKm1IVTmJB",
        "outputId": "6e97544b-9bf4-4a13-8363-52b9bdc6ae5f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2166</td>\n",
              "      <td>\"The establishment of a library is an ideal be...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1710</td>\n",
              "      <td>Loach is very engaged in everyday struggles of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1750</td>\n",
              "      <td>The Island ( theislandyork.org ) provides youn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1666</td>\n",
              "      <td>\"\"\" New thinking , new paradigms , new policie...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1485</td>\n",
              "      <td>England rout Windies in just three days in day...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3112</th>\n",
              "      <td>163</td>\n",
              "      <td>['in their imposing brick building, now few bl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3113</th>\n",
              "      <td>1911</td>\n",
              "      <td>To prevent minors and vulnerable persons from ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3114</th>\n",
              "      <td>1474</td>\n",
              "      <td>More than 200 people are resettled in Launcest...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3115</th>\n",
              "      <td>1954</td>\n",
              "      <td>THE Penang Island City Council ( MBPP ) took a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3116</th>\n",
              "      <td>1611</td>\n",
              "      <td>They said in the past two days the homeless re...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3117 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0                                              texts  labels\n",
              "0           2166  \"The establishment of a library is an ideal be...       1\n",
              "1           1710  Loach is very engaged in everyday struggles of...       0\n",
              "2           1750  The Island ( theislandyork.org ) provides youn...       0\n",
              "3           1666  \"\"\" New thinking , new paradigms , new policie...       0\n",
              "4           1485  England rout Windies in just three days in day...       0\n",
              "...          ...                                                ...     ...\n",
              "3112         163  ['in their imposing brick building, now few bl...       0\n",
              "3113        1911  To prevent minors and vulnerable persons from ...       0\n",
              "3114        1474  More than 200 people are resettled in Launcest...       0\n",
              "3115        1954  THE Penang Island City Council ( MBPP ) took a...       0\n",
              "3116        1611  They said in the past two days the homeless re...       0\n",
              "\n",
              "[3117 rows x 3 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set_augmented_balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "5330c8ed43e743e3a6a3a9a31d44ed04",
            "2b868d88f7be43deadd5a14157a35a6d",
            "5ed3eb99337147a0af95a4a3117a21f6"
          ]
        },
        "id": "uLuQfW2WTmJB",
        "outputId": "39b6ffdb-9b07-4b8c-87be-b88421e98c99"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5330c8ed43e743e3a6a3a9a31d44ed04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b868d88f7be43deadd5a14157a35a6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ed3eb99337147a0af95a4a3117a21f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/694 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# LONGFORMER\n",
        "\n",
        "# Create a function to tokenize the text and return the input ids, attention mask and labels as PyTorch tensors\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import LongformerTokenizer\n",
        "\n",
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, data_frame, tokenizer, max_seq_length):\n",
        "        self.data = data_frame\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = max_seq_length\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data.iloc[idx]['texts']\n",
        "        label = self.data.iloc[idx]['labels']\n",
        "        \n",
        "        # Tokenize text using LongformerTokenizer\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_seq_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        # Return inputs and label as PyTorch tensors\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].squeeze(),\n",
        "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Example usage:\n",
        "# Load the pandas DataFrame containing text samples and labels\n",
        "train_set_augmented_balanced = pd.read_csv('data/augmentations_200_.csv')\n",
        "\n",
        "# Initialize LongformerTokenizer and set max sequence length\n",
        "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "max_seq_length = 512\n",
        "\n",
        "# Create TextClassificationDataset instance\n",
        "train_dataset_long = TextClassificationDataset(train_set_augmented_balanced, tokenizer, max_seq_length)\n",
        "val_dataset_long = TextClassificationDataset(val_set, tokenizer, max_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUu-zJNsTmJC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import LongformerModel\n",
        "\n",
        "class LongformerForTextClassification(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Load the pretrained Longformer model\n",
        "        self.longformer = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n",
        "        \n",
        "        # Add a classification head on top of Longformer\n",
        "        self.classifier = nn.Linear(self.longformer.config.hidden_size, num_labels)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Pass inputs through Longformer\n",
        "        outputs = self.longformer(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=True\n",
        "        )\n",
        "        \n",
        "        # Use the last hidden state as input to the classification head\n",
        "        last_hidden_state = outputs.last_hidden_state\n",
        "        logits = self.classifier(last_hidden_state[:, 0, :])\n",
        "        \n",
        "        # Return logits\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuVsI2EpTmJC",
        "outputId": "136392b2-67db-4327-f076-27350625649c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
            "Model config LongformerConfig {\n",
            "  \"attention_mode\": \"longformer\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"attention_window\": [\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"ignore_attention_mask\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 4098,\n",
            "  \"model_type\": \"longformer\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"sep_token_id\": 2,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n",
            "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of LongformerModel were initialized from the model checkpoint at allenai/longformer-base-4096.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongformerModel for predictions without further training.\n",
            "  2%|▏         | 4/195 [03:39<2:54:38, 54.86s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y115sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y115sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y115sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y115sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "# Example usage:\n",
        "# Define training parameters\n",
        "# batch_size = 16\n",
        "# num_epochs = 10\n",
        "# learning_rate = 2e-5\n",
        "\n",
        "# Initialize model, optimizer and loss function\n",
        "# model = LongformerForTextClassification(num_labels=2)\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Create PyTorch DataLoader instance\n",
        "# dataloader = torch.utils.data.DataLoader(train_dataset_long, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "#for epoch in range(num_epochs):\n",
        "    # for batch in tqdm(dataloader):\n",
        "        # input_ids = batch['input_ids']\n",
        "        # attention_mask = batch['attention_mask']\n",
        "        # labels = batch['label']\n",
        "        \n",
        "        # Zero the gradients\n",
        "        # optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        # logits = model(input_ids, attention_mask)\n",
        "        # loss = loss_fn(logits, labels)\n",
        "        \n",
        "        # Backward pass\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "# In this example, we define some training parameters such as the batch size, number of epochs, and learning rate. We initialize the model, optimizer, and loss function, and create a PyTorch DataLoader instance from the dataset. We then iterate over the dataset using a for loop, compute the forward and backward passes, and update the model parameters using the optimizer.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1eKoYB-TmJD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class TextClassifierTrainer:\n",
        "    def __init__(self, model, train_dataset, val_dataset, batch_size, lr):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.train_dataset = train_dataset\n",
        "        self.val_dataset = val_dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        \n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        \n",
        "        self.train_dataloader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        self.val_dataloader = DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "        \n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.val_accs = []\n",
        "        \n",
        "    def train(self, num_epochs):\n",
        "        for epoch in range(num_epochs):\n",
        "            train_loss = 0.0\n",
        "            self.model.train()\n",
        "            for batch in self.train_dataloader:\n",
        "                self.optimizer.zero_grad()\n",
        "                input_ids = batch['input_ids'].to(self.device)\n",
        "                attention_mask = batch['attention_mask'].to(self.device)\n",
        "                labels = batch['label'].to(self.device)\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask)\n",
        "                loss = self.loss_fn(outputs.logits, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                train_loss += loss.item() * input_ids.size(0)\n",
        "            \n",
        "            train_loss = train_loss / len(self.train_dataset)\n",
        "            self.train_losses.append(train_loss)\n",
        "            \n",
        "            val_loss, val_acc = self.evaluate()\n",
        "            self.val_losses.append(val_loss)\n",
        "            self.val_accs.append(val_acc)\n",
        "            \n",
        "            print(f'Epoch {epoch+1}: Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f} | Val acc: {val_acc:.4f}')\n",
        "            \n",
        "    def evaluate(self):\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in self.val_dataloader:\n",
        "                input_ids = batch['input_ids'].to(self.device)\n",
        "                attention_mask = batch['attention_mask'].to(self.device)\n",
        "                labels = batch['label'].to(self.device)\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask)\n",
        "                loss = self.loss_fn(outputs.logits, labels)\n",
        "                val_loss += loss.item() * input_ids.size(0)\n",
        "                preds = torch.argmax(outputs.logits, dim=1)\n",
        "                correct += torch.sum(preds == labels).item()\n",
        "                total += labels.size(0)\n",
        "            \n",
        "        val_loss = val_loss / len(self.val_dataset)\n",
        "        val_acc = correct / total\n",
        "        \n",
        "        return val_loss, val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "f9d19f79284f48cdb9d2e6d66c614286"
          ]
        },
        "id": "ZNHfOkCqTmJE",
        "outputId": "0852b126-5f2c-4697-804f-512b9fca2059"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9d19f79284f48cdb9d2e6d66c614286",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA out of memory. Tried to allocate 386.00 MiB (GPU 0; 23.88 GiB total capacity; 22.24 GiB already allocated; 278.50 MiB free; 22.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m LongformerForTextClassification(num_labels\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trainer \u001b[39m=\u001b[39m TextClassifierTrainer(model, train_dataset_long, val_dataset_long, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, lr\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(num_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
            "\u001b[1;32m/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb Cell 35\u001b[0m in \u001b[0;36mTextClassifierTrainer.train\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m attention_mask \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m labels \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(input_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn(outputs\u001b[39m.\u001b[39mlogits, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32m/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb Cell 35\u001b[0m in \u001b[0;36mLongformerForTextClassification.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_ids, attention_mask):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# Pass inputs through Longformer\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlongformer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m# Use the last hidden state as input to the classification head\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y121sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     last_hidden_state \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlast_hidden_state\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/longformer/modeling_longformer.py:1715\u001b[0m, in \u001b[0;36mLongformerModel.forward\u001b[0;34m(self, input_ids, attention_mask, global_attention_mask, head_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1707\u001b[0m extended_attention_mask: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_extended_attention_mask(attention_mask, input_shape)[\n\u001b[1;32m   1708\u001b[0m     :, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, :\n\u001b[1;32m   1709\u001b[0m ]\n\u001b[1;32m   1711\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1712\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids, position_ids\u001b[39m=\u001b[39mposition_ids, token_type_ids\u001b[39m=\u001b[39mtoken_type_ids, inputs_embeds\u001b[39m=\u001b[39minputs_embeds\n\u001b[1;32m   1713\u001b[0m )\n\u001b[0;32m-> 1715\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1716\u001b[0m     embedding_output,\n\u001b[1;32m   1717\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1718\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1719\u001b[0m     padding_len\u001b[39m=\u001b[39;49mpadding_len,\n\u001b[1;32m   1720\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1721\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1722\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1723\u001b[0m )\n\u001b[1;32m   1724\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1725\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/longformer/modeling_longformer.py:1297\u001b[0m, in \u001b[0;36mLongformerEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, padding_len, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m   1289\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1290\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         is_index_global_attn,\n\u001b[1;32m   1295\u001b[0m     )\n\u001b[1;32m   1296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1297\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1298\u001b[0m         hidden_states,\n\u001b[1;32m   1299\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1300\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mhead_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1301\u001b[0m         is_index_masked\u001b[39m=\u001b[39;49mis_index_masked,\n\u001b[1;32m   1302\u001b[0m         is_index_global_attn\u001b[39m=\u001b[39;49mis_index_global_attn,\n\u001b[1;32m   1303\u001b[0m         is_global_attn\u001b[39m=\u001b[39;49mis_global_attn,\n\u001b[1;32m   1304\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1305\u001b[0m     )\n\u001b[1;32m   1306\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1308\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m   1309\u001b[0m     \u001b[39m# bzs x seq_len x num_attn_heads x (num_global_attn + attention_window_len + 1) => bzs x num_attn_heads x seq_len x (num_global_attn + attention_window_len + 1)\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/longformer/modeling_longformer.py:1221\u001b[0m, in \u001b[0;36mLongformerLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m   1212\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1213\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1219\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1220\u001b[0m ):\n\u001b[0;32m-> 1221\u001b[0m     self_attn_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m   1222\u001b[0m         hidden_states,\n\u001b[1;32m   1223\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1224\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1225\u001b[0m         is_index_masked\u001b[39m=\u001b[39;49mis_index_masked,\n\u001b[1;32m   1226\u001b[0m         is_index_global_attn\u001b[39m=\u001b[39;49mis_index_global_attn,\n\u001b[1;32m   1227\u001b[0m         is_global_attn\u001b[39m=\u001b[39;49mis_global_attn,\n\u001b[1;32m   1228\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1229\u001b[0m     )\n\u001b[1;32m   1230\u001b[0m     attn_output \u001b[39m=\u001b[39m self_attn_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1231\u001b[0m     outputs \u001b[39m=\u001b[39m self_attn_outputs[\u001b[39m1\u001b[39m:]\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/longformer/modeling_longformer.py:1157\u001b[0m, in \u001b[0;36mLongformerAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m   1148\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1149\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1155\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m ):\n\u001b[0;32m-> 1157\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m   1158\u001b[0m         hidden_states,\n\u001b[1;32m   1159\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1160\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1161\u001b[0m         is_index_masked\u001b[39m=\u001b[39;49mis_index_masked,\n\u001b[1;32m   1162\u001b[0m         is_index_global_attn\u001b[39m=\u001b[39;49mis_index_global_attn,\n\u001b[1;32m   1163\u001b[0m         is_global_attn\u001b[39m=\u001b[39;49mis_global_attn,\n\u001b[1;32m   1164\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1165\u001b[0m     )\n\u001b[1;32m   1166\u001b[0m     attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m   1167\u001b[0m     outputs \u001b[39m=\u001b[39m (attn_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/longformer/modeling_longformer.py:635\u001b[0m, in \u001b[0;36mLongformerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[39m# free memory\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mdel\u001b[39;00m global_key_attn_scores\n\u001b[0;32m--> 635\u001b[0m attn_probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49msoftmax(\n\u001b[1;32m    636\u001b[0m     attn_scores, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32\n\u001b[1;32m    637\u001b[0m )  \u001b[39m# use fp32 for numerical stability\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[39mif\u001b[39;00m layer_head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    640\u001b[0m     \u001b[39massert\u001b[39;00m layer_head_mask\u001b[39m.\u001b[39msize() \u001b[39m==\u001b[39m (\n\u001b[1;32m    641\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m    642\u001b[0m     ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHead mask for a single layer should be of size \u001b[39m\u001b[39m{\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,)\u001b[39m}\u001b[39;00m\u001b[39m, but is \u001b[39m\u001b[39m{\u001b[39;00mlayer_head_mask\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1836\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim)\n\u001b[1;32m   1835\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1836\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m   1837\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 386.00 MiB (GPU 0; 23.88 GiB total capacity; 22.24 GiB already allocated; 278.50 MiB free; 22.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "\n",
        "model = LongformerForTextClassification(num_labels=2)\n",
        "trainer = TextClassifierTrainer(model, train_dataset_long, val_dataset_long, batch_size=32, lr=1e-5)\n",
        "trainer.train(num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqtToTG6TmJF"
      },
      "source": [
        "## WORKING BERT MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eUoMXanTmJF"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "class TextClassificationDatasetBert(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, data_frame, max_len):\n",
        "        self.data = data_frame\n",
        "        self.max_len = max_len\n",
        "        self.texts = data_frame['texts'].values\n",
        "        \n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        text = self.data.iloc[item]['texts']\n",
        "        label = self.data.iloc[item]['labels']\n",
        "        \n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MifyREFiTmJF"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class BertClassification(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.linear = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.linear(pooled_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW0lepucTmJG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import f1_score\n",
        "import tqdm\n",
        "\n",
        "\n",
        "class BertTrainer:\n",
        "    def __init__(self, model, train_dataset, val_dataset=None, test_dataset=None, batch_size=32, lr=2e-5, num_epochs=3):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "        self.train_dataset = train_dataset\n",
        "        self.val_dataset = val_dataset\n",
        "        self.test_dataset = test_dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        self.num_epochs = num_epochs\n",
        "        \n",
        "        self.optimizer = AdamW(self.model.parameters(), lr=self.lr)\n",
        "        self.scheduler = get_linear_schedule_with_warmup(self.optimizer, num_warmup_steps=0, num_training_steps=len(self.train_dataset)*self.num_epochs)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        \n",
        "    def train(self):\n",
        "        train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False) if self.val_dataset else None\n",
        "        test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False) if self.test_dataset else None\n",
        "        \n",
        "        for epoch in range(self.num_epochs):\n",
        "            self.model.train()\n",
        "            train_loss, train_acc, train_f1 = 0.0, 0.0, 0.0\n",
        "            with tqdm.tqdm(train_loader, unit=\"batch\") as tepoch: \n",
        "                for i, batch in enumerate(tepoch):\n",
        "                    self.optimizer.zero_grad()\n",
        "                    input_ids = batch['input_ids'].to(self.device)\n",
        "                    attention_mask = batch['attention_mask'].to(self.device)\n",
        "                    labels = batch['label'].to(self.device)\n",
        "                    logits = self.model(input_ids, attention_mask)\n",
        "                    loss = self.loss_fn(logits, labels)\n",
        "                    loss.backward()\n",
        "                    nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "                    self.optimizer.step()\n",
        "                    self.scheduler.step()\n",
        "                    train_loss += loss.item()\n",
        "                    train_acc += (logits.argmax(dim=-1) == labels).sum().item()\n",
        "                    train_f1 += f1_score(labels.cpu(), logits.cpu().argmax(dim=-1), average='weighted')\n",
        "                    if i % 20 == 0:\n",
        "                        tepoch.set_description(f\"Epoch {epoch}/{self.num_epochs}\")\n",
        "                        tepoch.set_postfix(Loss = f\"{train_loss/(i+1):.4f}\", Accuracy = f\"{train_acc/((i+1)*self.batch_size):.4f}\", F1 = f\"{train_f1/(i+1):.4f}\")\n",
        "            train_loss /= len(train_loader)\n",
        "            train_acc /= len(self.train_dataset)\n",
        "            train_f1 /= len(train_loader)\n",
        "            print(f\"Epoch: {epoch+1}/{self.num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f} Train F1: {train_f1:.4f}\")\n",
        "            \n",
        "            if val_loader:\n",
        "                val_loss, val_acc, val_f1 = self.evaluate(val_loader)\n",
        "                print(f\"Epoch: {epoch+1}/{self.num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f} Validation F1: {val_f1:.4f}\")\n",
        "                \n",
        "        if test_loader:\n",
        "            test_loss, test_acc, test_f1 = self.evaluate(test_loader)\n",
        "            print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}, Test F1: {test_f1:.4f}\")\n",
        "        \n",
        "    def evaluate(self, dataloader):\n",
        "        self.model.eval()\n",
        "        eval_loss, eval_acc, eval_f1 = 0.0, 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            with tqdm.tqdm(dataloader, unit=\"batch\") as tepoch:\n",
        "                for idx, batch in enumerate(tepoch):\n",
        "                    input_ids = batch['input_ids'].to(self.device)\n",
        "                    attention_mask = batch['attention_mask'].to(self.device)\n",
        "                    batch['attention_mask'].to(self.device)\n",
        "                    labels = batch['label'].to(self.device)\n",
        "                    logits = self.model(input_ids, attention_mask)\n",
        "                    loss = self.loss_fn(logits, labels)\n",
        "                    eval_loss += loss.item()\n",
        "                    eval_acc += (logits.argmax(dim=-1) == labels).sum().item()\n",
        "                    eval_f1 += f1_score(labels.cpu(), logits.argmax(dim=-1).cpu(), average='weighted')\n",
        "                    tepoch.set_description(f\"Validation\")\n",
        "                    tepoch.set_postfix(Loss = f\"{eval_loss/(idx+1):.4f}\", Accuracy = f\"{eval_acc/((idx+1)*self.batch_size):.4f}\", F1 = f\"{eval_f1/(idx+1):.4f}\")\n",
        "                eval_loss /= len(dataloader)\n",
        "                eval_acc /= len(self.val_dataset)\n",
        "                eval_f1 /= len(dataloader)\n",
        "                    \n",
        "            \n",
        "        return eval_loss, eval_acc, eval_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhU3AZFOTmJG"
      },
      "outputs": [],
      "source": [
        "train_dataset_bert = TextClassificationDatasetBert(train_set_augmented_balanced, max_len=128)\n",
        "val_dataset_bert = TextClassificationDatasetBert(val_set, max_len=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_07lfBy4TmJH",
        "outputId": "a28cfc7d-d67c-43d2-9094-b1853308389f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 0/3: 100%|██████████| 195/195 [00:46<00:00,  4.16batch/s, Accuracy=0.7607, F1=0.7181, Loss=0.4840]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/3, Train Loss: 0.4823, Train Accuracy: 0.7629 Train F1: 0.7224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 27/27 [00:02<00:00,  9.82batch/s, Accuracy=0.8032, F1=0.8148, Loss=0.4421]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/3, Validation Loss: 0.4421, Validation Accuracy: 0.8184 Validation F1: 0.8148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3: 100%|██████████| 195/195 [00:48<00:00,  4.05batch/s, Accuracy=0.8650, F1=0.8626, Loss=0.3178]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2/3, Train Loss: 0.3179, Train Accuracy: 0.8653 Train F1: 0.8630\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 27/27 [00:02<00:00, 10.08batch/s, Accuracy=0.8472, F1=0.8561, Loss=0.3430]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2/3, Validation Loss: 0.3430, Validation Accuracy: 0.8632 Validation F1: 0.8561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/3: 100%|██████████| 195/195 [00:48<00:00,  4.05batch/s, Accuracy=0.9430, F1=0.9426, Loss=0.1683]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3/3, Train Loss: 0.1705, Train Accuracy: 0.9429 Train F1: 0.9424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 27/27 [00:02<00:00,  9.55batch/s, Accuracy=0.8866, F1=0.9068, Loss=0.2871]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3/3, Validation Loss: 0.2871, Validation Accuracy: 0.9033 Validation F1: 0.9068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model = BertClassification(num_classes=2)\n",
        "\n",
        "# Initialize the trainer\n",
        "trainer = BertTrainer(model, train_dataset=train_dataset_bert, val_dataset=val_dataset_bert, batch_size=16, lr=2e-5, num_epochs=3)\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR7OX587TmJH"
      },
      "source": [
        "### CODE BELOW DOESN'T WORK "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SH3nXRx0TmJH"
      },
      "outputs": [],
      "source": [
        "### END OF THE "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Gpw63IXTmJI"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qilKxg3WTmJI"
      },
      "outputs": [],
      "source": [
        "# Taken from lab 5\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Create DPMDataset class to load data into the model\n",
        "# During each iteration, the model will receive a batch of texts and labels\n",
        "# method __getitem__ will be called to return a batch of texts and labels\n",
        "# Then, the ''collate_fn'' function will process the list of samples into their encodings and return a batch when called by the iterator during training\n",
        "\n",
        "\n",
        "\n",
        "class DPMDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer, input_set):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = input_set['texts']\n",
        "        self.labels = input_set['labels']\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "#if idx < len(self.texts):\n",
        "          item = {'text': self.texts[idx],\n",
        "                'label': self.labels[idx]}\n",
        "\n",
        "          return item\n",
        "\n",
        "#else:\n",
        "#return \n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "\n",
        "\n",
        "\n",
        "        texts = []\n",
        "        labels = []\n",
        "\n",
        "\n",
        "\n",
        "        for b in batch:\n",
        "            texts.append(b['text'])\n",
        "            labels.append(b['label'])\n",
        "\n",
        "        #The maximum sequence size for BERT is 512 but here the tokenizer truncate sentences longer than 128 tokens.  \n",
        "        # We also pad shorter sentences to a length of 128 tokens\n",
        "\n",
        "        encodings = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=300)\n",
        "\n",
        "        labels_all = {}\n",
        "        #encodings['text'] = torch.tensor(texts)\n",
        "        encodings['label'] =  torch.tensor(labels)\n",
        "        return encodings\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I73OIPmSTmJI",
        "outputId": "66736e69-c098-4ea2-c1e8-c81ff9c9129c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
            "loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
            "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ten0wWTzTmJJ"
      },
      "outputs": [],
      "source": [
        "# Create train and validation datasets\n",
        "\n",
        "max_len = 128\n",
        "train_dataset = DPMDataset(tokenizer, train_set_augmented_balanced)\n",
        "\n",
        "val_dataset = DPMDataset(tokenizer, val_set)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riG_EVYITmJJ"
      },
      "source": [
        "## Trying Longformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nskbew-TTmJJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import datasets\n",
        "from transformers import LongformerTokenizerFast, LongformerForSequenceClassification, Trainer, TrainingArguments, LongformerConfig\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoDKDu_-TmJK",
        "outputId": "bbf6007f-2da6-45ed-9579-4d39933a1fbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LongformerConfig {\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"attention_window\": 512,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"longformer\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 1,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"sep_token_id\": 2,\n",
              "  \"transformers_version\": \"4.20.1\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30522\n",
              "}"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config = LongformerConfig()\n",
        "\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5BJrURMTmJK"
      },
      "outputs": [],
      "source": [
        "API = 'a18126ca7a6f1fe683e47a1e2f0e546590106fb3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6AVu-RQTmJK",
        "outputId": "6a250787-13af-40d1-ce12-244833f95fa9"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'wandb' has no attribute 'API'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb Cell 38\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#Y110sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m wandb\u001b[39m.\u001b[39;49mAPI(API)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'wandb' has no attribute 'API'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17JhUVO_TmJK",
        "outputId": "0f639717-c4cd-497d-88a1-719f6a4ea12b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ6zxKZITmJK"
      },
      "source": [
        "## BERT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1P1L4hSTmJL"
      },
      "outputs": [],
      "source": [
        "# Define the BERT model for classification\n",
        "\n",
        "class DPM_BERT(RobertaPreTrainedModel): \n",
        "    \n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.roberta = BertModel(config)\n",
        "        self.projection = torch.nn.Sequential(nn.Dropout(0.2), nn.Linear(config.hidden_size, 2))\n",
        "        self.init_weights()\n",
        "    \n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, labels=None, output_attentions=None, output_hidden_states=None, return_dict=None):\n",
        "        \n",
        "        outputs = self.roberta(input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask= head_mask, \n",
        "            output_attentions = output_attentions, \n",
        "            output_hidden_states = output_hidden_states,\n",
        "            return_dict = return_dict)\n",
        "        \n",
        "        logits = self.projection(outputs[1])\n",
        "\n",
        "        return logits # (loss), logits, (hidden_states), (attentions)\n",
        "    \n",
        "    def freeze_bert_encoder(self):\n",
        "        for param in self.roberta.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def unfreeze_bert_encoder(self):\n",
        "        for param in self.roberta.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "# Create the model\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-Pe8tT9TmJL"
      },
      "outputs": [],
      "source": [
        "# Define a trainer class to train the model\n",
        "\n",
        "class DPM_Trainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = {}\n",
        "        labels['label'] = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        labels = labels['label']\n",
        "\n",
        "\n",
        "        loss_fct = nn.CrossEntropyLoss()\n",
        "        loss = loss_fct(outputs.view(-1, 2), labels.view(-1))\n",
        "        loss = loss\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "904CECK0TmJL"
      },
      "outputs": [],
      "source": [
        "def training(train_dataset, val_dataset, num_train_epochs, learning_rate, per_device_train_batch_size, per_device_eval_batch_size):\n",
        "\n",
        "    model = DPM_BERT.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "\n",
        "    # Define the training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',          # output directory\n",
        "        num_train_epochs=num_train_epochs,              # total number of training epochs\n",
        "        per_device_train_batch_size=per_device_train_batch_size, # batch size per device during training\n",
        "        per_device_eval_batch_size=per_device_eval_batch_size,   # batch size for evaluation\n",
        "        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "        weight_decay=0.01,               # strength of weight decay\n",
        "        logging_dir='./logs',            # directory for storing logs\n",
        "        logging_steps=10,\n",
        "        evaluation_strategy='epoch',\n",
        "        save_strategy='epoch',\n",
        "        save_total_limit=1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='F1',\n",
        "        greater_is_better=True,\n",
        "        learning_rate=learning_rate,\n",
        "        adam_epsilon=1e-8,\n",
        "        dataloader_num_workers=4,\n",
        "        report_to='none', \n",
        "        lr_scheduler_type='linear'\n",
        "    )\n",
        "\n",
        "    trainer = DPM_Trainer(\n",
        "        model=model,                         # the instantiated huggingFace Transformers model to be trained\n",
        "        args=training_args,                  # training arguments, defined above\n",
        "        train_dataset=train_dataset,         # training dataset \n",
        "        eval_dataset=val_dataset,            # evaluation dataset\n",
        "        data_collator=train_dataset.collate_fn,\n",
        "                    \n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the model\n",
        "    trainer.save_model()\n",
        "\n",
        "    # Evaluate the model\n",
        "    trainer.evaluate()\n",
        "\n",
        "    return trainer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCOj5Fs0TmJM",
        "outputId": "a6baa198-6100-4b8b-bd79-32620053a3bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
            "You are using a model of type bert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing DPM_BERT: ['bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.pooler.dense.bias', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.3.output.dense.bias', 'cls.predictions.bias', 'bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.bias', 'cls.seq_relationship.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.embeddings.LayerNorm.bias', 'bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.output.dense.weight', 'cls.seq_relationship.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.pooler.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.4.attention.output.dense.bias', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.9.attention.self.value.bias']\n",
            "- This IS expected if you are initializing DPM_BERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPM_BERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DPM_BERT were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'projection.1.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'projection.1.bias', 'pooler.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'embeddings.position_ids', 'encoder.layer.0.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 3117\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 975\n",
            "The following columns in the training set don't have a corresponding argument in `DPM_BERT.forward` and have been ignored: text. If text are not expected by `DPM_BERT.forward`,  you can safely ignore this message.\n",
            "The following columns in the training set don't have a corresponding argument in `DPM_BERT.forward` and have been ignored: text. If text are not expected by `DPM_BERT.forward`,  you can safely ignore this message.\n",
            "The following columns in the training set don't have a corresponding argument in `DPM_BERT.forward` and have been ignored: text. If text are not expected by `DPM_BERT.forward`,  you can safely ignore this message.\n",
            "The following columns in the training set don't have a corresponding argument in `DPM_BERT.forward` and have been ignored: text. If text are not expected by `DPM_BERT.forward`,  you can safely ignore this message.\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.9/dist-packages/transformers/trainer_utils.py\", line 696, in __call__\n    return self.data_collator(features)\n  File \"/tmp/ipykernel_425/1427992435.py\", line 38, in collate_fn\n    texts.append(b['text'])\nKeyError: 'text'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb Cell 38\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X65sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m training( train_dataset, val_dataset, learning_rate \u001b[39m=\u001b[39;49m \u001b[39m2e-5\u001b[39;49m, num_train_epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, per_device_train_batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, per_device_eval_batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m)\n",
            "\u001b[1;32m/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb Cell 38\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(train_dataset, val_dataset, num_train_epochs, learning_rate, per_device_train_batch_size, per_device_eval_batch_size)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X65sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m trainer \u001b[39m=\u001b[39m DPM_Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X65sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,                         \u001b[39m# the instantiated huggingFace Transformers model to be trained\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X65sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,                  \u001b[39m# training arguments, defined above\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X65sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m                 \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X65sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X65sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X65sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X65sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Save the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X65sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m trainer\u001b[39m.\u001b[39msave_model()\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:1409\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1406\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1407\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1408\u001b[0m )\n\u001b[0;32m-> 1409\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1410\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1411\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1412\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1413\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1414\u001b[0m )\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:1625\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_rng_state(resume_from_checkpoint)\n\u001b[1;32m   1624\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m-> 1625\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1626\u001b[0m \n\u001b[1;32m   1627\u001b[0m     \u001b[39m# Skip past any already trained steps if resuming training\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m     \u001b[39mif\u001b[39;00m steps_trained_in_current_epoch \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1629\u001b[0m         steps_trained_in_current_epoch \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:1347\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1347\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:1373\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1373\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1374\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 461\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
            "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.9/dist-packages/transformers/trainer_utils.py\", line 696, in __call__\n    return self.data_collator(features)\n  File \"/tmp/ipykernel_425/1427992435.py\", line 38, in collate_fn\n    texts.append(b['text'])\nKeyError: 'text'\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "\n",
        "training( train_dataset, val_dataset, learning_rate = 2e-5, num_train_epochs=5, per_device_train_batch_size=16, per_device_eval_batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48hwRpL_TmJM"
      },
      "outputs": [],
      "source": [
        "# Create a dataloader for the training set\n",
        "\n",
        "train_data_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "    num_workers=4,\n",
        "    collate_fn=train_dataset.collate_fn\n",
        ")\n",
        "\n",
        "# Create a dataloader for the validation set\n",
        "\n",
        "val_data_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=16,\n",
        "    num_workers=4,\n",
        "    collate_fn=val_dataset.collate_fn\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xhNkTm7TmJM"
      },
      "outputs": [],
      "source": [
        "# Define the training loop\n",
        "\n",
        "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
        "\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    for d in data_loader:\n",
        "        \n",
        "        texts = d[\"texts\"]\n",
        "        input_ids = d[\"input_ids\"].to(device)\n",
        "        attention_mask = d[\"attention_mask\"].to(device)\n",
        "        targets = d[\"targets\"].to(device)\n",
        "        \n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        \n",
        "        _, preds = torch.max(outputs[0], dim=1)\n",
        "        loss = loss_fn(outputs[0], targets)\n",
        "        \n",
        "        correct_predictions += torch.sum(preds == targets)\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "\n",
        "# Define the evaluation loop\n",
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "    model = model.eval()\n",
        "    \n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            \n",
        "            texts = d[\"texts\"]\n",
        "            input_ids = d[\"input_ids\"].to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            targets = d[\"targets\"].to(device)\n",
        "            \n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "            \n",
        "            _, preds = torch.max(outputs[0], dim=1)\n",
        "            \n",
        "            loss = loss_fn(outputs[0], targets)\n",
        "            \n",
        "            correct_predictions += torch.sum(preds == targets)\n",
        "            losses.append(loss.item())\n",
        "            \n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCFiMwr_TmJN"
      },
      "outputs": [],
      "source": [
        "# Import the AdamW optimizer and the learning rate scheduler\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Hxe5udiTmJN"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "fc49efeb1821474b8c4fa2286e738b50"
          ]
        },
        "id": "7ECHIY9aTmJN",
        "outputId": "a81b1feb-cfd0-46f5-e1a1-22101bd18a98"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc49efeb1821474b8c4fa2286e738b50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "----------\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_32/217650699.py\", line 36, in __getitem__\n    'targets': torch.tensor(target, dtype=torch.long)\nValueError: too many dimensions 'Series'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mEPOCHS\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m10\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m train_acc, train_loss \u001b[39m=\u001b[39m train_epoch(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m train_data_loader,    \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m loss_fn, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m optimizer, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m device, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m scheduler, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mlen\u001b[39;49m(train_set_augmented_balanced)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrain loss \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m}\u001b[39;00m\u001b[39m accuracy \u001b[39m\u001b[39m{\u001b[39;00mtrain_acc\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m val_acc, val_loss \u001b[39m=\u001b[39m eval_model(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m val_data_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mlen\u001b[39m(val_set)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m )\n",
            "\u001b[1;32m/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb Cell 37\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m correct_predictions \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     texts \u001b[39m=\u001b[39m d[\u001b[39m\"\u001b[39m\u001b[39mtexts\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/anastasia/Desktop/NLP_W/NLP_CW1.ipynb#X56sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     input_ids \u001b[39m=\u001b[39m d[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:1347\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1347\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:1373\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1373\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1374\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 461\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
            "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_32/217650699.py\", line 36, in __getitem__\n    'targets': torch.tensor(target, dtype=torch.long)\nValueError: too many dimensions 'Series'\n"
          ]
        }
      ],
      "source": [
        "# Run the training loop\n",
        "\n",
        "# Define the training parameters\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup( optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=total_steps)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# Run the training loop\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "        \n",
        "        print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "        print('-' * 10)\n",
        "        \n",
        "        train_acc, train_loss = train_epoch(\n",
        "        model,\n",
        "        train_data_loader,    \n",
        "        loss_fn, \n",
        "        optimizer, \n",
        "        device, \n",
        "        scheduler, \n",
        "        len(train_set_augmented_balanced)\n",
        "        )\n",
        "        \n",
        "        print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "        \n",
        "        val_acc, val_loss = eval_model(\n",
        "        model,\n",
        "        val_data_loader,\n",
        "        loss_fn, \n",
        "        device, \n",
        "        len(val_set)\n",
        "        )\n",
        "        \n",
        "        print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "        print()\n",
        "    \n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        \n",
        "        if val_acc > best_accuracy:\n",
        "            torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "            best_accuracy = val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DISTIL BERT"
      ],
      "metadata": {
        "id": "OCvu5mPgUIhx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b-ZeCAX4ULbL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qUz2KZJv5dTG",
        "t4_IzClSTmI9",
        "7qvTBf0hTmI9",
        "rj5DNrVzTmI_",
        "rujfTK7YTmJA",
        "bqtToTG6TmJF",
        "oR7OX587TmJH",
        "riG_EVYITmJJ",
        "EZ6zxKZITmJK"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}